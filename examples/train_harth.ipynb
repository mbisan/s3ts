{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from storage.har_datasets import HARTHDataset, UCI_HARDataset, sts_medoids\n",
    "from s3ts.api.dms.har_datasets import LDFDataset, DFDataset\n",
    "from storage.label_mappings import *\n",
    "from s3ts.api.nets.methods import create_model_from_DM, train_model, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'walking',\n",
       " 2: 'running',\n",
       " 3: 'shuffling',\n",
       " 4: 'stairs_up',\n",
       " 5: 'stairs_down',\n",
       " 6: 'standing',\n",
       " 7: 'sitting',\n",
       " 8: 'lying',\n",
       " 13: 'cycking_sit',\n",
       " 14: 'cycling_stand',\n",
       " 130: 'cycling_sit_idle',\n",
       " 140: 'cycling_stand_idle'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HARTH_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = np.zeros(141)\n",
    "label_mapping[1:9] = np.arange(8)\n",
    "label_mapping[13] = 8\n",
    "label_mapping[14] = 9\n",
    "label_mapping[130] = 10\n",
    "label_mapping[140] = 11\n",
    "\n",
    "ds = HARTHDataset(\"./datasets/HARTH/\", wsize=48, normalize=True, label_mapping=label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6225494"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./datasets/HARTH/meds.npz\"):\n",
    "    meds = sts_medoids(ds, n=500)\n",
    "    with open(\"./datasets/HARTH/meds.npz\", \"wb\") as f:\n",
    "        np.save(f, meds)\n",
    "else:\n",
    "    meds = np.load(\"./datasets/HARTH/meds.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached dissimilarity frames if available...\n"
     ]
    }
   ],
   "source": [
    "dfds = DFDataset(ds, patterns=meds, w=0.1, dm_transform=None, ram=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DM = []\n",
    "\n",
    "np.random.seed(42)\n",
    "for i in np.random.choice(np.arange(len(dfds)), 500):\n",
    "    dm, _, _ = dfds[i]\n",
    "    DM.append(dm)\n",
    "\n",
    "DM = torch.stack(DM)\n",
    "\n",
    "dm_transform = Normalize(mean=DM.mean(dim=[0, 2, 3]), std=DM.std(dim=[0, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfds.dm_transform = dm_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = {\n",
    "    \"train\": lambda x: x<6000000,\n",
    "    \"val\": lambda x: (x>=6000000) * (x<6050000),\n",
    "    \"test\": lambda x: x>=6050000\n",
    "}\n",
    "\n",
    "dm = LDFDataset(dfds, data_split=data_split, batch_size=32, random_seed=42, num_workers=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6225494"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dm.ds_train) + len(dm.ds_val) + len(dm.ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([1, 12, 48, 48])\n",
      "Latent shape:  torch.Size([1, 40, 3, 48])\n"
     ]
    }
   ],
   "source": [
    "model = create_model_from_DM(dm, name=None, \n",
    "        dsrc=\"img\", arch=\"cnn\", task=\"cls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: training/img_cnn_cls_wl48_ws1_ss0_np12_lp48_n12\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name       | Type               | Params\n",
      "---------------------------------------------------\n",
      "0  | encoder    | CNN_IMG            | 24.7 K\n",
      "1  | decoder    | LinearDecoder      | 377 K \n",
      "2  | flatten    | Flatten            | 0     \n",
      "3  | softmax    | Softmax            | 0     \n",
      "4  | train_acc  | MulticlassAccuracy | 0     \n",
      "5  | train_f1   | MulticlassF1Score  | 0     \n",
      "6  | val_acc    | MulticlassAccuracy | 0     \n",
      "7  | val_f1     | MulticlassF1Score  | 0     \n",
      "8  | val_auroc  | MulticlassAUROC    | 0     \n",
      "9  | test_acc   | MulticlassAccuracy | 0     \n",
      "10 | test_f1    | MulticlassF1Score  | 0     \n",
      "11 | test_auroc | MulticlassAUROC    | 0     \n",
      "---------------------------------------------------\n",
      "402 K     Trainable params\n",
      "0         Non-trainable params\n",
      "402 K     Total params\n",
      "1.610     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 186561/186561 [30:17<00:00, 102.67it/s, v_num=0, train_loss_step=2.120, val_loss=1.680, val_acc=0.942, val_auroc=0.00102, train_loss_epoch=1.770, train_acc=0.852]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 186561/186561 [30:17<00:00, 102.67it/s, v_num=0, train_loss_step=2.120, val_loss=1.680, val_acc=0.942, val_auroc=0.00102, train_loss_epoch=1.770, train_acc=0.852]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape:  torch.Size([1, 12, 48, 48])\n",
      "Latent shape:  torch.Size([1, 40, 3, 48])\n",
      "Validation DataLoader 0: 100%|██████████| 1555/1555 [00:24<00:00, 63.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9420619010925293     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_auroc         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">   0.0010182209080085158   </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">          val_f1           </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9420619010925293     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         val_loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    1.6766694784164429     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9420619010925293    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_auroc        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m  0.0010182209080085158  \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m         val_f1          \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9420619010925293    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        val_loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   1.6766694784164429    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_acc': 0.9420619010925293, 'val_f1': 0.9420619010925293, 'val_auroc': 0.0010182209080085158}\n"
     ]
    }
   ],
   "source": [
    "model, data = train_model(dm, model, max_epochs=2)\n",
    "print(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssstsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
